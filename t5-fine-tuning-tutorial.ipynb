{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# T5 text-to-text transformer\n",
    "\n",
    "Hey guys I made this tutorial for all NLP lovers who are intrested to try current state of the art T5 transformer. For those who don't know what T5 is, here is the\n",
    "original paper link https://arxiv.org/abs/1910.10683. If you don't want to go through the whole paper check this [TowardDataScience article](https://towardsdatascience.com/t5-text-to-text-transformer-a-brief-paper-analysis-e4bba797bd68)."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "T5 is text to text transformer aimed to take text input and text output.What's special about it is you can solve any NLP problem using it."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "In this tutorial I will try how to use T5 for text extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/tweet-sentiment-extraction/sample_submission.csv\n",
      "/kaggle/input/tweet-sentiment-extraction/test.csv\n",
      "/kaggle/input/tweet-sentiment-extraction/train.csv\n",
      "/kaggle/input/tweetextract/val.csv\n",
      "/kaggle/input/tweetextract/test.csv\n",
      "/kaggle/input/tweetextract/train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 21 04:59:39 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   41C    P0    28W / 250W |      0MiB / 16280MiB |      4%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (2.9.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers) (1.18.1)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from transformers) (0.1.86)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2020.4.4)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.45.0)\r\n",
      "Requirement already satisfied: tokenizers==0.7.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.7.0)\r\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.43)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.23.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.10)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.14.0)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.1)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.24.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.4.5.1)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.9)\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "Collecting pytorch_lightning\r\n",
      "  Downloading pytorch_lightning-0.7.6-py3-none-any.whl (248 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 248 kB 2.3 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (0.18.2)\r\n",
      "Requirement already satisfied: numpy>=1.16.4 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (1.18.1)\r\n",
      "Requirement already satisfied: torch>=1.1 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (1.5.0)\r\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (4.45.0)\r\n",
      "Requirement already satisfied: pyyaml>=3.13 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (5.3.1)\r\n",
      "Requirement already satisfied: tensorboard>=1.14 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (2.1.1)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch_lightning) (1.14.0)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch_lightning) (0.9.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch_lightning) (3.2.1)\r\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch_lightning) (0.34.2)\r\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch_lightning) (1.28.1)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch_lightning) (1.0.1)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch_lightning) (2.23.0)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch_lightning) (46.1.3.post20200325)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch_lightning) (1.14.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch_lightning) (0.4.1)\r\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch_lightning) (3.11.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (2020.4.5.1)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (1.24.3)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (2.9)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning) (3.0.4)\r\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (4.0)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (0.2.7)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (3.1.1)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning) (1.2.0)\r\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning) (3.0.1)\r\n",
      "Installing collected packages: pytorch-lightning\r\n",
      "Successfully installed pytorch-lightning-0.7.6\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# T5 fine-tuning\n",
    "This notebook is to showcase how to fine-tune T5 model with Huggigface's Transformers to solve different NLP tasks using text-2-text approach proposed in the T5 paper. For demo I chose 3 non text-2-text problems just to reiterate the fact from the paper that how widely applicable this text-2-text framework is and how it can be used for different tasks without changing the model at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "from itertools import chain\n",
    "from string import punctuation\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Model\n",
    "We'll be using the awesome pytorch-lightning library for training. Most of the below code is adapted from here https://github.com/huggingface/transformers/blob/master/examples/lightning_base.py\n",
    "\n",
    "The trainer is generic and can be used for any text-2-text task. You'll just need to change the dataset. Rest of the code will stay unchanged for all the tasks.\n",
    "\n",
    "This is the most intresting and powrfull thing about the text-2-text format. You can fine-tune the model on variety of NLP tasks by just formulating the problem in text-2-text setting. No need to change hyperparameters, learning rate, optimizer or loss function. Just plug in your dataset and you are ready to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5FineTuner(pl.LightningModule):\n",
    "  def __init__(self, hparams):\n",
    "    super(T5FineTuner, self).__init__()\n",
    "    self.hparams = hparams\n",
    "    \n",
    "    self.model = T5ForConditionalGeneration.from_pretrained(hparams.model_name_or_path)\n",
    "    self.tokenizer = T5Tokenizer.from_pretrained(hparams.tokenizer_name_or_path)\n",
    "  \n",
    "  def is_logger(self):\n",
    "    return self.trainer.proc_rank <= 0\n",
    "  \n",
    "  def forward(\n",
    "      self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, lm_labels=None\n",
    "  ):\n",
    "    return self.model(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        decoder_input_ids=decoder_input_ids,\n",
    "        decoder_attention_mask=decoder_attention_mask,\n",
    "        lm_labels=lm_labels,\n",
    "    )\n",
    "\n",
    "  def _step(self, batch):\n",
    "    lm_labels = batch[\"target_ids\"]\n",
    "    lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "    outputs = self(\n",
    "        input_ids=batch[\"source_ids\"],\n",
    "        attention_mask=batch[\"source_mask\"],\n",
    "        lm_labels=lm_labels,\n",
    "        decoder_attention_mask=batch['target_mask']\n",
    "    )\n",
    "\n",
    "    loss = outputs[0]\n",
    "\n",
    "    return loss\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    loss = self._step(batch)\n",
    "\n",
    "    tensorboard_logs = {\"train_loss\": loss}\n",
    "    return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "  \n",
    "  def training_epoch_end(self, outputs):\n",
    "    avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "    tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n",
    "    return {\"avg_train_loss\": avg_train_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    loss = self._step(batch)\n",
    "    return {\"val_loss\": loss}\n",
    "  \n",
    "  def validation_epoch_end(self, outputs):\n",
    "    avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "    tensorboard_logs = {\"val_loss\": avg_loss}\n",
    "    return {\"avg_val_loss\": avg_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
    "\n",
    "    model = self.model\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": self.hparams.weight_decay,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n",
    "    self.opt = optimizer\n",
    "    return [optimizer]\n",
    "  \n",
    "  def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None):\n",
    "    if self.trainer.use_tpu:\n",
    "      xm.optimizer_step(optimizer)\n",
    "    else:\n",
    "      optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    self.lr_scheduler.step()\n",
    "  \n",
    "  def get_tqdm_dict(self):\n",
    "    tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n",
    "\n",
    "    return tqdm_dict\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    train_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"train\", args=self.hparams)\n",
    "    dataloader = DataLoader(train_dataset, batch_size=self.hparams.train_batch_size, drop_last=True, shuffle=True, num_workers=4)\n",
    "    t_total = (\n",
    "        (len(dataloader.dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n",
    "        // self.hparams.gradient_accumulation_steps\n",
    "        * float(self.hparams.num_train_epochs)\n",
    "    )\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        self.opt, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=t_total\n",
    "    )\n",
    "    self.lr_scheduler = scheduler\n",
    "    return dataloader\n",
    "\n",
    "  def val_dataloader(self):\n",
    "    val_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"val\", args=self.hparams)\n",
    "    return DataLoader(val_dataset, batch_size=self.hparams.eval_batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class LoggingCallback(pl.Callback):\n",
    "  def on_validation_end(self, trainer, pl_module):\n",
    "    logger.info(\"***** Validation results *****\")\n",
    "    if pl_module.is_logger():\n",
    "      metrics = trainer.callback_metrics\n",
    "      # Log results\n",
    "      for key in sorted(metrics):\n",
    "        if key not in [\"log\", \"progress_bar\"]:\n",
    "          logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "\n",
    "  def on_test_end(self, trainer, pl_module):\n",
    "    logger.info(\"***** Test results *****\")\n",
    "\n",
    "    if pl_module.is_logger():\n",
    "      metrics = trainer.callback_metrics\n",
    "\n",
    "      # Log and save results to file\n",
    "      output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n",
    "      with open(output_test_results_file, \"w\") as writer:\n",
    "        for key in sorted(metrics):\n",
    "          if key not in [\"log\", \"progress_bar\"]:\n",
    "            logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "            writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Let's define the hyperparameters and other arguments. You can overide this dict for specific task as needed. While in most of cases you'll only need to change the data_dirand output_dir.\n",
    "\n",
    "Here the batch size is 8 and gradient_accumulation_steps are 16 so the effective batch size is 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = dict(\n",
    "    data_dir=\"\", # path for data files\n",
    "    output_dir=\"\", # path to save the checkpoints\n",
    "    model_name_or_path='t5-base',\n",
    "    tokenizer_name_or_path='t5-base',\n",
    "    max_seq_length=512,\n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=0.0,\n",
    "    adam_epsilon=1e-8,\n",
    "    warmup_steps=0,\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    gradient_accumulation_steps=16,\n",
    "    n_gpu=1,\n",
    "    early_stop_callback=False,\n",
    "    fp_16=False, # if you want to enable 16-bit training then install apex and set this to true\n",
    "    opt_level='O1', # you can find out more on optimisation levels here https://nvidia.github.io/apex/amp.html#opt-levels-and-properties\n",
    "    max_grad_norm=1.0, # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "```\n",
    "/kaggle/input/tweetextract/val.csv\n",
    "\n",
    "\n",
    "/kaggle/input/tweetextract/test.csv\n",
    "\n",
    "\n",
    "/kaggle/input/tweetextract/train.csv ```"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "I divided the training data into train and val with 22k and 5k rows and uploaded it on tweetextract folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from enum import Enum\n",
    "from typing import List, Optional\n",
    "from transformers import PreTrainedTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## The only thing you need to understand is how to dataset as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class InputExample:\n",
    "  example_id : str\n",
    "  text : str\n",
    "  sentiment : str\n",
    "  label : str\n",
    "  \"\"\"\n",
    "    A single training/test example for multiple choice\n",
    "    Args:\n",
    "        example_id: Unique id for the example.\n",
    "        contexts: list of str. The untokenized text of the first sequence (context of corresponding question).\n",
    "        answer : str containing answer for which we need to generate question\n",
    "        label: string containg questions\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "class Split(Enum):\n",
    "    train = \"train\"\n",
    "    dev = \"dev\"\n",
    "    test = \"test\"\n",
    "\n",
    "class DataProcessor:\n",
    "    \"\"\"Base class for data converters for multiple choice data sets.\"\"\"\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the test set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "class SwagProcessor(DataProcessor):\n",
    "    \"\"\"Processor for the SWAG data set.\"\"\"\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        logger.info(\"LOOKING AT {} train\".format(data_dir))\n",
    "        return self._create_examples(self._read_csv(os.path.join(data_dir, \"train.csv\")), \"train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        logger.info(\"LOOKING AT {} dev\".format(data_dir))\n",
    "        return self._create_examples(self._read_csv(os.path.join(data_dir, \"val.csv\")), \"dev\")\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        logger.info(\"LOOKING AT {} dev\".format(data_dir))\n",
    "        raise ValueError(\n",
    "            \"For swag testing, the input file does not contain a label column. It can not be tested in current code\"\n",
    "            \"setting!\"\n",
    "        )\n",
    "        return self._create_examples(self._read_csv(os.path.join(data_dir, \"test.csv\")), \"test\")\n",
    "\n",
    "    \n",
    "\n",
    "    def _read_csv(self, input_file):\n",
    "        with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            return list(csv.reader(f))\n",
    "\n",
    "    def _create_examples(self, lines: List[List[str]], type: str):\n",
    "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "        if type == \"train\" and lines[0][2] != \"selected_text\":\n",
    "            raise ValueError(\"For training, the input file must contain a label column.\")\n",
    "\n",
    "        examples = [\n",
    "            InputExample(\n",
    "                example_id=line[0],\n",
    "                # common beginning of each\n",
    "                # choice is stored in \"sent2\".\n",
    "                text=line[1],\n",
    "                sentiment=line[3],\n",
    "                label=line[2]\n",
    "\n",
    "            )\n",
    "            for line in lines[1:]  # we skip the line with the column names\n",
    "        ]\n",
    "\n",
    "        return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "  def __init__(self, tokenizer, data_dir, type_path,  max_len=512):\n",
    "    self.data_dir = data_dir\n",
    "    self.type_path = type_path\n",
    "    self.max_len = max_len\n",
    "    self.tokenizer = tokenizer\n",
    "    self.inputs = []\n",
    "    self.targets = []\n",
    "\n",
    "    self.proc = SwagProcessor()\n",
    "\n",
    "    self._build()\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    source_ids = self.inputs[index][\"input_ids\"].squeeze()\n",
    "    target_ids = self.targets[index][\"input_ids\"].squeeze()\n",
    "\n",
    "    src_mask    = self.inputs[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
    "    target_mask = self.targets[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
    "\n",
    "    return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.inputs)\n",
    "  \n",
    "  def _build(self):\n",
    "    if self.type_path == 'train':\n",
    "      examples = self.proc.get_train_examples(self.data_dir)\n",
    "    else:\n",
    "      examples = self.proc.get_dev_examples(self.data_dir)\n",
    "    \n",
    "    for example in examples:\n",
    "      self._create_features(example)\n",
    "  \n",
    "  def _create_features(self, example):\n",
    "    input_ = example.text\n",
    "    answer = example.sentiment\n",
    "    input_ = \"text: %s  sentiment: %s </s>\" % (input_, answer)\n",
    "    target = example.label\n",
    "    target = \"%s </s>\" % (str(target))\n",
    "\n",
    "    # tokenize inputs\n",
    "    tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
    "        [input_], max_length=self.max_len, pad_to_max_length=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    # tokenize targets\n",
    "    tokenized_targets = self.tokenizer.batch_encode_plus(\n",
    "        [target], max_length=150, pad_to_max_length=True, return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    self.inputs.append(tokenized_inputs)\n",
    "    self.targets.append(tokenized_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "862d5f8ad2334331afceec2f27a50a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TweetDataset(tokenizer, data_dir='/kaggle/input/tweetextract/', type_path='val')\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: If you know such agent, do let me know sentiment: neutral\n",
      "If you know such agent, do let me know\n"
     ]
    }
   ],
   "source": [
    "data = dataset[69]\n",
    "print(tokenizer.decode(data['source_ids']))\n",
    "print(tokenizer.decode(data['target_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /kaggle/working/t5_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_dir': '/kaggle/input/tweetextract/', 'output_dir': '/kaggle/working/t5_tweet/', 'model_name_or_path': 't5-base', 'tokenizer_name_or_path': 't5-base', 'max_seq_length': 512, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'warmup_steps': 0, 'train_batch_size': 8, 'eval_batch_size': 8, 'num_train_epochs': 1, 'gradient_accumulation_steps': 16, 'n_gpu': 1, 'early_stop_callback': False, 'fp_16': False, 'opt_level': 'O1', 'max_grad_norm': 1.0, 'seed': 42}\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p /kaggle/working/t5_tweet\n",
    "args_dict.update({'data_dir': '/kaggle/input/tweetextract/', 'output_dir': '/kaggle/working/t5_tweet/', 'num_train_epochs': 1})\n",
    "args = argparse.Namespace(**args_dict)\n",
    "print(args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    filepath=args.output_dir, prefix=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=5\n",
    ")\n",
    "\n",
    "train_params = dict(\n",
    "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
    "    gpus=args.n_gpu,\n",
    "    max_epochs=args.num_train_epochs,\n",
    "    early_stop_callback=False,\n",
    "    precision= 16 if args.fp_16 else 32,\n",
    "    amp_level=args.opt_level,\n",
    "    gradient_clip_val=args.max_grad_norm,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    callbacks=[LoggingCallback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(tokenizer, type_path, args):\n",
    "  return TweetDataset(tokenizer=tokenizer, data_dir=args.data_dir, type_path=type_path,  max_len=args.max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd719c4a6684945a2bf3ecd80f79052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1199.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dff0dabd7af4ff4987e7066d2ef14e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=891691430.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = T5FineTuner(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "No environment variable for node rank defined. Set as 0.\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBLIB_TEMP_FOLDER=/tmp\n"
     ]
    }
   ],
   "source": [
    "%env JOBLIB_TEMP_FOLDER=/tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    | Name                                                                  | Type                       | Params\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "0   | model                                                                 | T5ForConditionalGeneration | 222 M \n",
      "1   | model.shared                                                          | Embedding                  | 24 M  \n",
      "2   | model.encoder                                                         | T5Stack                    | 109 M \n",
      "3   | model.encoder.block                                                   | ModuleList                 | 84 M  \n",
      "4   | model.encoder.block.0                                                 | T5Block                    | 7 M   \n",
      "5   | model.encoder.block.0.layer                                           | ModuleList                 | 7 M   \n",
      "6   | model.encoder.block.0.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "7   | model.encoder.block.0.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "8   | model.encoder.block.0.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "9   | model.encoder.block.0.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "10  | model.encoder.block.0.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "11  | model.encoder.block.0.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "12  | model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias   | Embedding                  | 384   \n",
      "13  | model.encoder.block.0.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "14  | model.encoder.block.0.layer.0.dropout                                 | Dropout                    | 0     \n",
      "15  | model.encoder.block.0.layer.1                                         | T5LayerFF                  | 4 M   \n",
      "16  | model.encoder.block.0.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "17  | model.encoder.block.0.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "18  | model.encoder.block.0.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "19  | model.encoder.block.0.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "20  | model.encoder.block.0.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "21  | model.encoder.block.0.layer.1.dropout                                 | Dropout                    | 0     \n",
      "22  | model.encoder.block.1                                                 | T5Block                    | 7 M   \n",
      "23  | model.encoder.block.1.layer                                           | ModuleList                 | 7 M   \n",
      "24  | model.encoder.block.1.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "25  | model.encoder.block.1.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "26  | model.encoder.block.1.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "27  | model.encoder.block.1.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "28  | model.encoder.block.1.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "29  | model.encoder.block.1.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "30  | model.encoder.block.1.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "31  | model.encoder.block.1.layer.0.dropout                                 | Dropout                    | 0     \n",
      "32  | model.encoder.block.1.layer.1                                         | T5LayerFF                  | 4 M   \n",
      "33  | model.encoder.block.1.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "34  | model.encoder.block.1.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "35  | model.encoder.block.1.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "36  | model.encoder.block.1.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "37  | model.encoder.block.1.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "38  | model.encoder.block.1.layer.1.dropout                                 | Dropout                    | 0     \n",
      "39  | model.encoder.block.2                                                 | T5Block                    | 7 M   \n",
      "40  | model.encoder.block.2.layer                                           | ModuleList                 | 7 M   \n",
      "41  | model.encoder.block.2.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "42  | model.encoder.block.2.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "43  | model.encoder.block.2.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "44  | model.encoder.block.2.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "45  | model.encoder.block.2.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "46  | model.encoder.block.2.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "47  | model.encoder.block.2.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "48  | model.encoder.block.2.layer.0.dropout                                 | Dropout                    | 0     \n",
      "49  | model.encoder.block.2.layer.1                                         | T5LayerFF                  | 4 M   \n",
      "50  | model.encoder.block.2.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "51  | model.encoder.block.2.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "52  | model.encoder.block.2.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "53  | model.encoder.block.2.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "54  | model.encoder.block.2.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "55  | model.encoder.block.2.layer.1.dropout                                 | Dropout                    | 0     \n",
      "56  | model.encoder.block.3                                                 | T5Block                    | 7 M   \n",
      "57  | model.encoder.block.3.layer                                           | ModuleList                 | 7 M   \n",
      "58  | model.encoder.block.3.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "59  | model.encoder.block.3.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "60  | model.encoder.block.3.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "61  | model.encoder.block.3.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "62  | model.encoder.block.3.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "63  | model.encoder.block.3.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "64  | model.encoder.block.3.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "65  | model.encoder.block.3.layer.0.dropout                                 | Dropout                    | 0     \n",
      "66  | model.encoder.block.3.layer.1                                         | T5LayerFF                  | 4 M   \n",
      "67  | model.encoder.block.3.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "68  | model.encoder.block.3.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "69  | model.encoder.block.3.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "70  | model.encoder.block.3.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "71  | model.encoder.block.3.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "72  | model.encoder.block.3.layer.1.dropout                                 | Dropout                    | 0     \n",
      "73  | model.encoder.block.4                                                 | T5Block                    | 7 M   \n",
      "74  | model.encoder.block.4.layer                                           | ModuleList                 | 7 M   \n",
      "75  | model.encoder.block.4.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "76  | model.encoder.block.4.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "77  | model.encoder.block.4.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "78  | model.encoder.block.4.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "79  | model.encoder.block.4.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "80  | model.encoder.block.4.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "81  | model.encoder.block.4.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "82  | model.encoder.block.4.layer.0.dropout                                 | Dropout                    | 0     \n",
      "83  | model.encoder.block.4.layer.1                                         | T5LayerFF                  | 4 M   \n",
      "84  | model.encoder.block.4.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "85  | model.encoder.block.4.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "86  | model.encoder.block.4.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "87  | model.encoder.block.4.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "88  | model.encoder.block.4.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "89  | model.encoder.block.4.layer.1.dropout                                 | Dropout                    | 0     \n",
      "90  | model.encoder.block.5                                                 | T5Block                    | 7 M   \n",
      "91  | model.encoder.block.5.layer                                           | ModuleList                 | 7 M   \n",
      "92  | model.encoder.block.5.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "93  | model.encoder.block.5.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "94  | model.encoder.block.5.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "95  | model.encoder.block.5.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "96  | model.encoder.block.5.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "97  | model.encoder.block.5.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "98  | model.encoder.block.5.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "99  | model.encoder.block.5.layer.0.dropout                                 | Dropout                    | 0     \n",
      "100 | model.encoder.block.5.layer.1                                         | T5LayerFF                  | 4 M   \n",
      "101 | model.encoder.block.5.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "102 | model.encoder.block.5.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "103 | model.encoder.block.5.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "104 | model.encoder.block.5.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "105 | model.encoder.block.5.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "106 | model.encoder.block.5.layer.1.dropout                                 | Dropout                    | 0     \n",
      "107 | model.encoder.block.6                                                 | T5Block                    | 7 M   \n",
      "108 | model.encoder.block.6.layer                                           | ModuleList                 | 7 M   \n",
      "109 | model.encoder.block.6.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "110 | model.encoder.block.6.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "111 | model.encoder.block.6.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "112 | model.encoder.block.6.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "113 | model.encoder.block.6.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "114 | model.encoder.block.6.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "115 | model.encoder.block.6.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "116 | model.encoder.block.6.layer.0.dropout                                 | Dropout                    | 0     \n",
      "117 | model.encoder.block.6.layer.1                                         | T5LayerFF                  | 4 M   \n",
      "118 | model.encoder.block.6.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "119 | model.encoder.block.6.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "120 | model.encoder.block.6.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "121 | model.encoder.block.6.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "122 | model.encoder.block.6.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "123 | model.encoder.block.6.layer.1.dropout                                 | Dropout                    | 0     \n",
      "124 | model.encoder.block.7                                                 | T5Block                    | 7 M   \n",
      "125 | model.encoder.block.7.layer                                           | ModuleList                 | 7 M   \n",
      "126 | model.encoder.block.7.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "127 | model.encoder.block.7.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "128 | model.encoder.block.7.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "129 | model.encoder.block.7.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "130 | model.encoder.block.7.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "131 | model.encoder.block.7.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "132 | model.encoder.block.7.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "133 | model.encoder.block.7.layer.0.dropout                                 | Dropout                    | 0     \n",
      "134 | model.encoder.block.7.layer.1                                         | T5LayerFF                  | 4 M   \n",
      "135 | model.encoder.block.7.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "136 | model.encoder.block.7.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "137 | model.encoder.block.7.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "138 | model.encoder.block.7.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "139 | model.encoder.block.7.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "140 | model.encoder.block.7.layer.1.dropout                                 | Dropout                    | 0     \n",
      "141 | model.encoder.block.8                                                 | T5Block                    | 7 M   \n",
      "142 | model.encoder.block.8.layer                                           | ModuleList                 | 7 M   \n",
      "143 | model.encoder.block.8.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "144 | model.encoder.block.8.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "145 | model.encoder.block.8.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "146 | model.encoder.block.8.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "147 | model.encoder.block.8.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "148 | model.encoder.block.8.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "149 | model.encoder.block.8.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "150 | model.encoder.block.8.layer.0.dropout                                 | Dropout                    | 0     \n",
      "151 | model.encoder.block.8.layer.1                                         | T5LayerFF                  | 4 M   \n",
      "152 | model.encoder.block.8.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "153 | model.encoder.block.8.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "154 | model.encoder.block.8.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "155 | model.encoder.block.8.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "156 | model.encoder.block.8.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "157 | model.encoder.block.8.layer.1.dropout                                 | Dropout                    | 0     \n",
      "158 | model.encoder.block.9                                                 | T5Block                    | 7 M   \n",
      "159 | model.encoder.block.9.layer                                           | ModuleList                 | 7 M   \n",
      "160 | model.encoder.block.9.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "161 | model.encoder.block.9.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "162 | model.encoder.block.9.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "163 | model.encoder.block.9.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "164 | model.encoder.block.9.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "165 | model.encoder.block.9.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "166 | model.encoder.block.9.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "167 | model.encoder.block.9.layer.0.dropout                                 | Dropout                    | 0     \n",
      "168 | model.encoder.block.9.layer.1                                         | T5LayerFF                  | 4 M   \n",
      "169 | model.encoder.block.9.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "170 | model.encoder.block.9.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "171 | model.encoder.block.9.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "172 | model.encoder.block.9.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "173 | model.encoder.block.9.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "174 | model.encoder.block.9.layer.1.dropout                                 | Dropout                    | 0     \n",
      "175 | model.encoder.block.10                                                | T5Block                    | 7 M   \n",
      "176 | model.encoder.block.10.layer                                          | ModuleList                 | 7 M   \n",
      "177 | model.encoder.block.10.layer.0                                        | T5LayerSelfAttention       | 2 M   \n",
      "178 | model.encoder.block.10.layer.0.SelfAttention                          | T5Attention                | 2 M   \n",
      "179 | model.encoder.block.10.layer.0.SelfAttention.q                        | Linear                     | 589 K \n",
      "180 | model.encoder.block.10.layer.0.SelfAttention.k                        | Linear                     | 589 K \n",
      "181 | model.encoder.block.10.layer.0.SelfAttention.v                        | Linear                     | 589 K \n",
      "182 | model.encoder.block.10.layer.0.SelfAttention.o                        | Linear                     | 589 K \n",
      "183 | model.encoder.block.10.layer.0.layer_norm                             | T5LayerNorm                | 768   \n",
      "184 | model.encoder.block.10.layer.0.dropout                                | Dropout                    | 0     \n",
      "185 | model.encoder.block.10.layer.1                                        | T5LayerFF                  | 4 M   \n",
      "186 | model.encoder.block.10.layer.1.DenseReluDense                         | T5DenseReluDense           | 4 M   \n",
      "187 | model.encoder.block.10.layer.1.DenseReluDense.wi                      | Linear                     | 2 M   \n",
      "188 | model.encoder.block.10.layer.1.DenseReluDense.wo                      | Linear                     | 2 M   \n",
      "189 | model.encoder.block.10.layer.1.DenseReluDense.dropout                 | Dropout                    | 0     \n",
      "190 | model.encoder.block.10.layer.1.layer_norm                             | T5LayerNorm                | 768   \n",
      "191 | model.encoder.block.10.layer.1.dropout                                | Dropout                    | 0     \n",
      "192 | model.encoder.block.11                                                | T5Block                    | 7 M   \n",
      "193 | model.encoder.block.11.layer                                          | ModuleList                 | 7 M   \n",
      "194 | model.encoder.block.11.layer.0                                        | T5LayerSelfAttention       | 2 M   \n",
      "195 | model.encoder.block.11.layer.0.SelfAttention                          | T5Attention                | 2 M   \n",
      "196 | model.encoder.block.11.layer.0.SelfAttention.q                        | Linear                     | 589 K \n",
      "197 | model.encoder.block.11.layer.0.SelfAttention.k                        | Linear                     | 589 K \n",
      "198 | model.encoder.block.11.layer.0.SelfAttention.v                        | Linear                     | 589 K \n",
      "199 | model.encoder.block.11.layer.0.SelfAttention.o                        | Linear                     | 589 K \n",
      "200 | model.encoder.block.11.layer.0.layer_norm                             | T5LayerNorm                | 768   \n",
      "201 | model.encoder.block.11.layer.0.dropout                                | Dropout                    | 0     \n",
      "202 | model.encoder.block.11.layer.1                                        | T5LayerFF                  | 4 M   \n",
      "203 | model.encoder.block.11.layer.1.DenseReluDense                         | T5DenseReluDense           | 4 M   \n",
      "204 | model.encoder.block.11.layer.1.DenseReluDense.wi                      | Linear                     | 2 M   \n",
      "205 | model.encoder.block.11.layer.1.DenseReluDense.wo                      | Linear                     | 2 M   \n",
      "206 | model.encoder.block.11.layer.1.DenseReluDense.dropout                 | Dropout                    | 0     \n",
      "207 | model.encoder.block.11.layer.1.layer_norm                             | T5LayerNorm                | 768   \n",
      "208 | model.encoder.block.11.layer.1.dropout                                | Dropout                    | 0     \n",
      "209 | model.encoder.final_layer_norm                                        | T5LayerNorm                | 768   \n",
      "210 | model.encoder.dropout                                                 | Dropout                    | 0     \n",
      "211 | model.decoder                                                         | T5Stack                    | 137 M \n",
      "212 | model.decoder.block                                                   | ModuleList                 | 113 M \n",
      "213 | model.decoder.block.0                                                 | T5Block                    | 9 M   \n",
      "214 | model.decoder.block.0.layer                                           | ModuleList                 | 9 M   \n",
      "215 | model.decoder.block.0.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "216 | model.decoder.block.0.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "217 | model.decoder.block.0.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "218 | model.decoder.block.0.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "219 | model.decoder.block.0.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "220 | model.decoder.block.0.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "221 | model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias   | Embedding                  | 384   \n",
      "222 | model.decoder.block.0.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "223 | model.decoder.block.0.layer.0.dropout                                 | Dropout                    | 0     \n",
      "224 | model.decoder.block.0.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
      "225 | model.decoder.block.0.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
      "226 | model.decoder.block.0.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
      "227 | model.decoder.block.0.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
      "228 | model.decoder.block.0.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
      "229 | model.decoder.block.0.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
      "230 | model.decoder.block.0.layer.1.EncDecAttention.relative_attention_bias | Embedding                  | 384   \n",
      "231 | model.decoder.block.0.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "232 | model.decoder.block.0.layer.1.dropout                                 | Dropout                    | 0     \n",
      "233 | model.decoder.block.0.layer.2                                         | T5LayerFF                  | 4 M   \n",
      "234 | model.decoder.block.0.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "235 | model.decoder.block.0.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "236 | model.decoder.block.0.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "237 | model.decoder.block.0.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "238 | model.decoder.block.0.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
      "239 | model.decoder.block.0.layer.2.dropout                                 | Dropout                    | 0     \n",
      "240 | model.decoder.block.1                                                 | T5Block                    | 9 M   \n",
      "241 | model.decoder.block.1.layer                                           | ModuleList                 | 9 M   \n",
      "242 | model.decoder.block.1.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "243 | model.decoder.block.1.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "244 | model.decoder.block.1.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "245 | model.decoder.block.1.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "246 | model.decoder.block.1.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "247 | model.decoder.block.1.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "248 | model.decoder.block.1.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "249 | model.decoder.block.1.layer.0.dropout                                 | Dropout                    | 0     \n",
      "250 | model.decoder.block.1.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
      "251 | model.decoder.block.1.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
      "252 | model.decoder.block.1.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
      "253 | model.decoder.block.1.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
      "254 | model.decoder.block.1.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
      "255 | model.decoder.block.1.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
      "256 | model.decoder.block.1.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "257 | model.decoder.block.1.layer.1.dropout                                 | Dropout                    | 0     \n",
      "258 | model.decoder.block.1.layer.2                                         | T5LayerFF                  | 4 M   \n",
      "259 | model.decoder.block.1.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "260 | model.decoder.block.1.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "261 | model.decoder.block.1.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "262 | model.decoder.block.1.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "263 | model.decoder.block.1.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
      "264 | model.decoder.block.1.layer.2.dropout                                 | Dropout                    | 0     \n",
      "265 | model.decoder.block.2                                                 | T5Block                    | 9 M   \n",
      "266 | model.decoder.block.2.layer                                           | ModuleList                 | 9 M   \n",
      "267 | model.decoder.block.2.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "268 | model.decoder.block.2.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "269 | model.decoder.block.2.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "270 | model.decoder.block.2.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "271 | model.decoder.block.2.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "272 | model.decoder.block.2.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "273 | model.decoder.block.2.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "274 | model.decoder.block.2.layer.0.dropout                                 | Dropout                    | 0     \n",
      "275 | model.decoder.block.2.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
      "276 | model.decoder.block.2.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
      "277 | model.decoder.block.2.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
      "278 | model.decoder.block.2.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
      "279 | model.decoder.block.2.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
      "280 | model.decoder.block.2.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
      "281 | model.decoder.block.2.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "282 | model.decoder.block.2.layer.1.dropout                                 | Dropout                    | 0     \n",
      "283 | model.decoder.block.2.layer.2                                         | T5LayerFF                  | 4 M   \n",
      "284 | model.decoder.block.2.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "285 | model.decoder.block.2.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "286 | model.decoder.block.2.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "287 | model.decoder.block.2.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "288 | model.decoder.block.2.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
      "289 | model.decoder.block.2.layer.2.dropout                                 | Dropout                    | 0     \n",
      "290 | model.decoder.block.3                                                 | T5Block                    | 9 M   \n",
      "291 | model.decoder.block.3.layer                                           | ModuleList                 | 9 M   \n",
      "292 | model.decoder.block.3.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "293 | model.decoder.block.3.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "294 | model.decoder.block.3.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "295 | model.decoder.block.3.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "296 | model.decoder.block.3.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "297 | model.decoder.block.3.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "298 | model.decoder.block.3.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "299 | model.decoder.block.3.layer.0.dropout                                 | Dropout                    | 0     \n",
      "300 | model.decoder.block.3.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
      "301 | model.decoder.block.3.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
      "302 | model.decoder.block.3.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
      "303 | model.decoder.block.3.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
      "304 | model.decoder.block.3.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
      "305 | model.decoder.block.3.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
      "306 | model.decoder.block.3.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "307 | model.decoder.block.3.layer.1.dropout                                 | Dropout                    | 0     \n",
      "308 | model.decoder.block.3.layer.2                                         | T5LayerFF                  | 4 M   \n",
      "309 | model.decoder.block.3.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "310 | model.decoder.block.3.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "311 | model.decoder.block.3.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "312 | model.decoder.block.3.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "313 | model.decoder.block.3.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
      "314 | model.decoder.block.3.layer.2.dropout                                 | Dropout                    | 0     \n",
      "315 | model.decoder.block.4                                                 | T5Block                    | 9 M   \n",
      "316 | model.decoder.block.4.layer                                           | ModuleList                 | 9 M   \n",
      "317 | model.decoder.block.4.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "318 | model.decoder.block.4.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "319 | model.decoder.block.4.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "320 | model.decoder.block.4.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "321 | model.decoder.block.4.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "322 | model.decoder.block.4.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "323 | model.decoder.block.4.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "324 | model.decoder.block.4.layer.0.dropout                                 | Dropout                    | 0     \n",
      "325 | model.decoder.block.4.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
      "326 | model.decoder.block.4.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
      "327 | model.decoder.block.4.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
      "328 | model.decoder.block.4.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
      "329 | model.decoder.block.4.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
      "330 | model.decoder.block.4.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
      "331 | model.decoder.block.4.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "332 | model.decoder.block.4.layer.1.dropout                                 | Dropout                    | 0     \n",
      "333 | model.decoder.block.4.layer.2                                         | T5LayerFF                  | 4 M   \n",
      "334 | model.decoder.block.4.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "335 | model.decoder.block.4.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "336 | model.decoder.block.4.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "337 | model.decoder.block.4.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "338 | model.decoder.block.4.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
      "339 | model.decoder.block.4.layer.2.dropout                                 | Dropout                    | 0     \n",
      "340 | model.decoder.block.5                                                 | T5Block                    | 9 M   \n",
      "341 | model.decoder.block.5.layer                                           | ModuleList                 | 9 M   \n",
      "342 | model.decoder.block.5.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "343 | model.decoder.block.5.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "344 | model.decoder.block.5.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "345 | model.decoder.block.5.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "346 | model.decoder.block.5.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "347 | model.decoder.block.5.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "348 | model.decoder.block.5.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "349 | model.decoder.block.5.layer.0.dropout                                 | Dropout                    | 0     \n",
      "350 | model.decoder.block.5.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
      "351 | model.decoder.block.5.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
      "352 | model.decoder.block.5.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
      "353 | model.decoder.block.5.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
      "354 | model.decoder.block.5.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
      "355 | model.decoder.block.5.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
      "356 | model.decoder.block.5.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "357 | model.decoder.block.5.layer.1.dropout                                 | Dropout                    | 0     \n",
      "358 | model.decoder.block.5.layer.2                                         | T5LayerFF                  | 4 M   \n",
      "359 | model.decoder.block.5.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "360 | model.decoder.block.5.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "361 | model.decoder.block.5.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "362 | model.decoder.block.5.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "363 | model.decoder.block.5.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
      "364 | model.decoder.block.5.layer.2.dropout                                 | Dropout                    | 0     \n",
      "365 | model.decoder.block.6                                                 | T5Block                    | 9 M   \n",
      "366 | model.decoder.block.6.layer                                           | ModuleList                 | 9 M   \n",
      "367 | model.decoder.block.6.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "368 | model.decoder.block.6.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "369 | model.decoder.block.6.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "370 | model.decoder.block.6.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "371 | model.decoder.block.6.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "372 | model.decoder.block.6.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "373 | model.decoder.block.6.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "374 | model.decoder.block.6.layer.0.dropout                                 | Dropout                    | 0     \n",
      "375 | model.decoder.block.6.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
      "376 | model.decoder.block.6.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
      "377 | model.decoder.block.6.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
      "378 | model.decoder.block.6.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
      "379 | model.decoder.block.6.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
      "380 | model.decoder.block.6.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
      "381 | model.decoder.block.6.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "382 | model.decoder.block.6.layer.1.dropout                                 | Dropout                    | 0     \n",
      "383 | model.decoder.block.6.layer.2                                         | T5LayerFF                  | 4 M   \n",
      "384 | model.decoder.block.6.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "385 | model.decoder.block.6.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "386 | model.decoder.block.6.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "387 | model.decoder.block.6.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "388 | model.decoder.block.6.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
      "389 | model.decoder.block.6.layer.2.dropout                                 | Dropout                    | 0     \n",
      "390 | model.decoder.block.7                                                 | T5Block                    | 9 M   \n",
      "391 | model.decoder.block.7.layer                                           | ModuleList                 | 9 M   \n",
      "392 | model.decoder.block.7.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "393 | model.decoder.block.7.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "394 | model.decoder.block.7.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "395 | model.decoder.block.7.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "396 | model.decoder.block.7.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "397 | model.decoder.block.7.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "398 | model.decoder.block.7.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "399 | model.decoder.block.7.layer.0.dropout                                 | Dropout                    | 0     \n",
      "400 | model.decoder.block.7.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
      "401 | model.decoder.block.7.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
      "402 | model.decoder.block.7.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
      "403 | model.decoder.block.7.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
      "404 | model.decoder.block.7.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
      "405 | model.decoder.block.7.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
      "406 | model.decoder.block.7.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "407 | model.decoder.block.7.layer.1.dropout                                 | Dropout                    | 0     \n",
      "408 | model.decoder.block.7.layer.2                                         | T5LayerFF                  | 4 M   \n",
      "409 | model.decoder.block.7.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "410 | model.decoder.block.7.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "411 | model.decoder.block.7.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "412 | model.decoder.block.7.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "413 | model.decoder.block.7.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
      "414 | model.decoder.block.7.layer.2.dropout                                 | Dropout                    | 0     \n",
      "415 | model.decoder.block.8                                                 | T5Block                    | 9 M   \n",
      "416 | model.decoder.block.8.layer                                           | ModuleList                 | 9 M   \n",
      "417 | model.decoder.block.8.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "418 | model.decoder.block.8.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "419 | model.decoder.block.8.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "420 | model.decoder.block.8.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "421 | model.decoder.block.8.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "422 | model.decoder.block.8.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "423 | model.decoder.block.8.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "424 | model.decoder.block.8.layer.0.dropout                                 | Dropout                    | 0     \n",
      "425 | model.decoder.block.8.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
      "426 | model.decoder.block.8.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
      "427 | model.decoder.block.8.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
      "428 | model.decoder.block.8.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
      "429 | model.decoder.block.8.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
      "430 | model.decoder.block.8.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
      "431 | model.decoder.block.8.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "432 | model.decoder.block.8.layer.1.dropout                                 | Dropout                    | 0     \n",
      "433 | model.decoder.block.8.layer.2                                         | T5LayerFF                  | 4 M   \n",
      "434 | model.decoder.block.8.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "435 | model.decoder.block.8.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "436 | model.decoder.block.8.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "437 | model.decoder.block.8.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "438 | model.decoder.block.8.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
      "439 | model.decoder.block.8.layer.2.dropout                                 | Dropout                    | 0     \n",
      "440 | model.decoder.block.9                                                 | T5Block                    | 9 M   \n",
      "441 | model.decoder.block.9.layer                                           | ModuleList                 | 9 M   \n",
      "442 | model.decoder.block.9.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "443 | model.decoder.block.9.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "444 | model.decoder.block.9.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "445 | model.decoder.block.9.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "446 | model.decoder.block.9.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "447 | model.decoder.block.9.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "448 | model.decoder.block.9.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "449 | model.decoder.block.9.layer.0.dropout                                 | Dropout                    | 0     \n",
      "450 | model.decoder.block.9.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
      "451 | model.decoder.block.9.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
      "452 | model.decoder.block.9.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
      "453 | model.decoder.block.9.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
      "454 | model.decoder.block.9.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
      "455 | model.decoder.block.9.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
      "456 | model.decoder.block.9.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "457 | model.decoder.block.9.layer.1.dropout                                 | Dropout                    | 0     \n",
      "458 | model.decoder.block.9.layer.2                                         | T5LayerFF                  | 4 M   \n",
      "459 | model.decoder.block.9.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "460 | model.decoder.block.9.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "461 | model.decoder.block.9.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "462 | model.decoder.block.9.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "463 | model.decoder.block.9.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
      "464 | model.decoder.block.9.layer.2.dropout                                 | Dropout                    | 0     \n",
      "465 | model.decoder.block.10                                                | T5Block                    | 9 M   \n",
      "466 | model.decoder.block.10.layer                                          | ModuleList                 | 9 M   \n",
      "467 | model.decoder.block.10.layer.0                                        | T5LayerSelfAttention       | 2 M   \n",
      "468 | model.decoder.block.10.layer.0.SelfAttention                          | T5Attention                | 2 M   \n",
      "469 | model.decoder.block.10.layer.0.SelfAttention.q                        | Linear                     | 589 K \n",
      "470 | model.decoder.block.10.layer.0.SelfAttention.k                        | Linear                     | 589 K \n",
      "471 | model.decoder.block.10.layer.0.SelfAttention.v                        | Linear                     | 589 K \n",
      "472 | model.decoder.block.10.layer.0.SelfAttention.o                        | Linear                     | 589 K \n",
      "473 | model.decoder.block.10.layer.0.layer_norm                             | T5LayerNorm                | 768   \n",
      "474 | model.decoder.block.10.layer.0.dropout                                | Dropout                    | 0     \n",
      "475 | model.decoder.block.10.layer.1                                        | T5LayerCrossAttention      | 2 M   \n",
      "476 | model.decoder.block.10.layer.1.EncDecAttention                        | T5Attention                | 2 M   \n",
      "477 | model.decoder.block.10.layer.1.EncDecAttention.q                      | Linear                     | 589 K \n",
      "478 | model.decoder.block.10.layer.1.EncDecAttention.k                      | Linear                     | 589 K \n",
      "479 | model.decoder.block.10.layer.1.EncDecAttention.v                      | Linear                     | 589 K \n",
      "480 | model.decoder.block.10.layer.1.EncDecAttention.o                      | Linear                     | 589 K \n",
      "481 | model.decoder.block.10.layer.1.layer_norm                             | T5LayerNorm                | 768   \n",
      "482 | model.decoder.block.10.layer.1.dropout                                | Dropout                    | 0     \n",
      "483 | model.decoder.block.10.layer.2                                        | T5LayerFF                  | 4 M   \n",
      "484 | model.decoder.block.10.layer.2.DenseReluDense                         | T5DenseReluDense           | 4 M   \n",
      "485 | model.decoder.block.10.layer.2.DenseReluDense.wi                      | Linear                     | 2 M   \n",
      "486 | model.decoder.block.10.layer.2.DenseReluDense.wo                      | Linear                     | 2 M   \n",
      "487 | model.decoder.block.10.layer.2.DenseReluDense.dropout                 | Dropout                    | 0     \n",
      "488 | model.decoder.block.10.layer.2.layer_norm                             | T5LayerNorm                | 768   \n",
      "489 | model.decoder.block.10.layer.2.dropout                                | Dropout                    | 0     \n",
      "490 | model.decoder.block.11                                                | T5Block                    | 9 M   \n",
      "491 | model.decoder.block.11.layer                                          | ModuleList                 | 9 M   \n",
      "492 | model.decoder.block.11.layer.0                                        | T5LayerSelfAttention       | 2 M   \n",
      "493 | model.decoder.block.11.layer.0.SelfAttention                          | T5Attention                | 2 M   \n",
      "494 | model.decoder.block.11.layer.0.SelfAttention.q                        | Linear                     | 589 K \n",
      "495 | model.decoder.block.11.layer.0.SelfAttention.k                        | Linear                     | 589 K \n",
      "496 | model.decoder.block.11.layer.0.SelfAttention.v                        | Linear                     | 589 K \n",
      "497 | model.decoder.block.11.layer.0.SelfAttention.o                        | Linear                     | 589 K \n",
      "498 | model.decoder.block.11.layer.0.layer_norm                             | T5LayerNorm                | 768   \n",
      "499 | model.decoder.block.11.layer.0.dropout                                | Dropout                    | 0     \n",
      "500 | model.decoder.block.11.layer.1                                        | T5LayerCrossAttention      | 2 M   \n",
      "501 | model.decoder.block.11.layer.1.EncDecAttention                        | T5Attention                | 2 M   \n",
      "502 | model.decoder.block.11.layer.1.EncDecAttention.q                      | Linear                     | 589 K \n",
      "503 | model.decoder.block.11.layer.1.EncDecAttention.k                      | Linear                     | 589 K \n",
      "504 | model.decoder.block.11.layer.1.EncDecAttention.v                      | Linear                     | 589 K \n",
      "505 | model.decoder.block.11.layer.1.EncDecAttention.o                      | Linear                     | 589 K \n",
      "506 | model.decoder.block.11.layer.1.layer_norm                             | T5LayerNorm                | 768   \n",
      "507 | model.decoder.block.11.layer.1.dropout                                | Dropout                    | 0     \n",
      "508 | model.decoder.block.11.layer.2                                        | T5LayerFF                  | 4 M   \n",
      "509 | model.decoder.block.11.layer.2.DenseReluDense                         | T5DenseReluDense           | 4 M   \n",
      "510 | model.decoder.block.11.layer.2.DenseReluDense.wi                      | Linear                     | 2 M   \n",
      "511 | model.decoder.block.11.layer.2.DenseReluDense.wo                      | Linear                     | 2 M   \n",
      "512 | model.decoder.block.11.layer.2.DenseReluDense.dropout                 | Dropout                    | 0     \n",
      "513 | model.decoder.block.11.layer.2.layer_norm                             | T5LayerNorm                | 768   \n",
      "514 | model.decoder.block.11.layer.2.dropout                                | Dropout                    | 0     \n",
      "515 | model.decoder.final_layer_norm                                        | T5LayerNorm                | 768   \n",
      "516 | model.decoder.dropout                                                 | Dropout                    | 0     \n",
      "517 | model.lm_head                                                         | Linear                     | 24 M  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e4df3c3b3c4260b7110c20bbcfa68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02cfde10999645abaa20101d23ded048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1587428398394/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba2970cffa645d8bc3a5d22d8b33cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =  TweetDataset(tokenizer, data_dir='/kaggle/input/tweetextract/', type_path='val')\n",
    "loader = DataLoader(dataset, batch_size=32, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87531e7721a5440c9d9baa54e79b535e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=157.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.model.eval()\n",
    "outputs = []\n",
    "targets = []\n",
    "for batch in tqdm(loader):\n",
    "  outs = model.model.generate(input_ids=batch['source_ids'].cuda(), \n",
    "                              attention_mask=batch['source_mask'].cuda(), \n",
    "                              max_length=200)\n",
    "\n",
    "  dec = [tokenizer.decode(ids) for ids in outs]\n",
    "  target = [tokenizer.decode(ids) for ids in batch[\"target_ids\"]]\n",
    "  \n",
    "  outputs.extend(dec)\n",
    "  targets.extend(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv(\"/kaggle/input/tweetextract/val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[\"new_selected_text\"] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>new_selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I ⁇ d have responded, if I were going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>bullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>why couldn ⁇ t they put them on the releases w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \\\n",
       "0  I`d have responded, if I were going   neutral   \n",
       "1                             Sooo SAD  negative   \n",
       "2                          bullying me  negative   \n",
       "3                       leave me alone  negative   \n",
       "4                        Sons of ****,  negative   \n",
       "\n",
       "                                   new_selected_text  \n",
       "0              I ⁇ d have responded, if I were going  \n",
       "1                                               miss  \n",
       "2                                           bullying  \n",
       "3                     what interview! leave me alone  \n",
       "4  why couldn ⁇ t they put them on the releases w...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "02cfde10999645abaa20101d23ded048": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_49ecef3334fb4a2095ea43ca60fa740b",
        "IPY_MODEL_4d2a0cb3ded34fcc93f5e5e527c71bdf"
       ],
       "layout": "IPY_MODEL_2a48194edf704fef96aa222a8ba15238"
      }
     },
     "02ed96ad14f94a3789344a321c641c89": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "030a8c89ee054d65ae7cd2bab96919a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_75ea8e3b1c744df39ae1e1ad7107320d",
       "placeholder": "​",
       "style": "IPY_MODEL_49191a6044e8421db081d81d1339f7c2",
       "value": " 1.20k/1.20k [00:24&lt;00:00, 49.1B/s]"
      }
     },
     "050beeee84df40bfb0be06f4a14b5793": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b6d097cdd024479f87c1670e1761f14c",
       "max": 791656.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_be48ae575dac4832bba8659ab98e0740",
       "value": 791656.0
      }
     },
     "05923cf394a44897bf91ae7ce9bc7679": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_95ee3cac130e4afd90f07cfdff951e92",
       "max": 157.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_14ceaf04794045a2afb167e6b85f6646",
       "value": 157.0
      }
     },
     "060c4511a41f48f2b57f60f734cbf2be": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0d98f1f0e3e44943b84af68297c73809": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "14ceaf04794045a2afb167e6b85f6646": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "1869f6d3165a459fbee2a83b1e7b7d98": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "19e4df3c3b3c4260b7110c20bbcfa68f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_88f82a7d8c464cc8b1d5046473f8e963",
        "IPY_MODEL_eade61dda1a84948998955f45bc0cb35"
       ],
       "layout": "IPY_MODEL_bf5a09e257954c18ac8206766ebc9948"
      }
     },
     "1a8fb24fac89412f8e3a5dbce10ae13a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1ba2970cffa645d8bc3a5d22d8b33cf0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3652916c85f64bb8becaa5a60086e250",
        "IPY_MODEL_eaba976a8441491e94109cc0a44235b6"
       ],
       "layout": "IPY_MODEL_463f0b2d137b4381bddf58a71d6d4c5a"
      }
     },
     "1f99fe0d63fb4d148ed3652f8ecae814": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "277ced105d954aa59718eb4607506d29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "2a48194edf704fef96aa222a8ba15238": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "2bf1b8bef4d74092852a95da3eb8d957": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2d6af7e905bd4aff99a3a5013c59d814": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "3652916c85f64bb8becaa5a60086e250": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "Validating: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b31f106052794298a740b8df33db7a15",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b66c292e1f914b23a697f54850422ad0",
       "value": 1.0
      }
     },
     "3c02627fd1f74a13944b7740585ec3ab": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "405d9a2639f44be4999680bcbd44e368": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "463f0b2d137b4381bddf58a71d6d4c5a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "47f23abbed2d4ad38f598bec5d146e40": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_060c4511a41f48f2b57f60f734cbf2be",
       "max": 891691430.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a4328bd888734df19095b82b23beca74",
       "value": 891691430.0
      }
     },
     "49191a6044e8421db081d81d1339f7c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "49acd2be65164ba3b4d7529e74c6024b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "49ecef3334fb4a2095ea43ca60fa740b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Epoch 1: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_49acd2be65164ba3b4d7529e74c6024b",
       "max": 3435.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2d6af7e905bd4aff99a3a5013c59d814",
       "value": 3435.0
      }
     },
     "4d2a0cb3ded34fcc93f5e5e527c71bdf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_405d9a2639f44be4999680bcbd44e368",
       "placeholder": "​",
       "style": "IPY_MODEL_89e614ae9cdb4f899e0107a9b4e23480",
       "value": " 3435/3435 [37:49&lt;00:00,  1.51it/s, loss=0.016, v_num=0, val_loss=0.217]"
      }
     },
     "5d6cf2ca43f44f02b68c0d85a036b71a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "61c72b1faac04fd38f175bcba5e764f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a22ef2ddb7724515b38c9d379839cefc",
       "max": 1199.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e79692cb6b4c4480b719cbac845e9b12",
       "value": 1199.0
      }
     },
     "6b23035f2de648e9906c42b1e9aed1e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1f99fe0d63fb4d148ed3652f8ecae814",
       "placeholder": "​",
       "style": "IPY_MODEL_a350cc7a44a44075ad47954cd54e4e98",
       "value": " 792k/792k [00:00&lt;00:00, 7.14MB/s]"
      }
     },
     "75ea8e3b1c744df39ae1e1ad7107320d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7cd719c4a6684945a2bf3ecd80f79052": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_61c72b1faac04fd38f175bcba5e764f2",
        "IPY_MODEL_030a8c89ee054d65ae7cd2bab96919a2"
       ],
       "layout": "IPY_MODEL_1869f6d3165a459fbee2a83b1e7b7d98"
      }
     },
     "7fb5c5e5da4d4a5bab031abea44835c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a2710cf80f9746f19e4394ae83f852ea",
       "placeholder": "​",
       "style": "IPY_MODEL_82bcffe5a37d4ec6a984dbf748f3ee7d",
       "value": " 157/157 [04:10&lt;00:00,  1.59s/it]"
      }
     },
     "82bcffe5a37d4ec6a984dbf748f3ee7d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "862d5f8ad2334331afceec2f27a50a12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_050beeee84df40bfb0be06f4a14b5793",
        "IPY_MODEL_6b23035f2de648e9906c42b1e9aed1e7"
       ],
       "layout": "IPY_MODEL_d293392320d44ef88f666f236738fe7f"
      }
     },
     "87531e7721a5440c9d9baa54e79b535e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_05923cf394a44897bf91ae7ce9bc7679",
        "IPY_MODEL_7fb5c5e5da4d4a5bab031abea44835c0"
       ],
       "layout": "IPY_MODEL_3c02627fd1f74a13944b7740585ec3ab"
      }
     },
     "88f82a7d8c464cc8b1d5046473f8e963": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "Validation sanity check: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5d6cf2ca43f44f02b68c0d85a036b71a",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_277ced105d954aa59718eb4607506d29",
       "value": 1.0
      }
     },
     "89e614ae9cdb4f899e0107a9b4e23480": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "95ee3cac130e4afd90f07cfdff951e92": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "96dce8092fb54baba6f3bded36cabdd2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9dff0dabd7af4ff4987e7066d2ef14e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_47f23abbed2d4ad38f598bec5d146e40",
        "IPY_MODEL_be6fbba59e6b46719cda1720d8569d47"
       ],
       "layout": "IPY_MODEL_02ed96ad14f94a3789344a321c641c89"
      }
     },
     "a22ef2ddb7724515b38c9d379839cefc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a2710cf80f9746f19e4394ae83f852ea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a350cc7a44a44075ad47954cd54e4e98": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a4328bd888734df19095b82b23beca74": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "a89845b26dee4d4bbf9e59a87884bbd1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b31f106052794298a740b8df33db7a15": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b66c292e1f914b23a697f54850422ad0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "b6d097cdd024479f87c1670e1761f14c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "be48ae575dac4832bba8659ab98e0740": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "be6fbba59e6b46719cda1720d8569d47": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a89845b26dee4d4bbf9e59a87884bbd1",
       "placeholder": "​",
       "style": "IPY_MODEL_1a8fb24fac89412f8e3a5dbce10ae13a",
       "value": " 892M/892M [00:23&lt;00:00, 37.7MB/s]"
      }
     },
     "bf5a09e257954c18ac8206766ebc9948": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "d293392320d44ef88f666f236738fe7f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e79692cb6b4c4480b719cbac845e9b12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "e9159c6702d249b594ab1b4643aaaa15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "eaba976a8441491e94109cc0a44235b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2bf1b8bef4d74092852a95da3eb8d957",
       "placeholder": "​",
       "style": "IPY_MODEL_e9159c6702d249b594ab1b4643aaaa15",
       "value": " 625/625 [02:30&lt;00:00,  4.18it/s]"
      }
     },
     "eade61dda1a84948998955f45bc0cb35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_96dce8092fb54baba6f3bded36cabdd2",
       "placeholder": "​",
       "style": "IPY_MODEL_0d98f1f0e3e44943b84af68297c73809",
       "value": " 2/2 [00:01&lt;00:00,  1.04s/it]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
