{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Imports\nimport torch\nimport torchvision\nimport torch.nn as nn # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\nimport torch.optim as optim # For all Optimization algorithms, SGD, Adam, etc.\nimport torch.nn.functional as F # All functions that don't have any parameters\nfrom torch.utils.data import DataLoader # Gives easier dataset managment and creates mini batches\nimport torchvision.datasets as datasets # Has standard datasets we can import in a nice way\nimport torchvision.transforms as transforms # Transformations we can perform on our dataset","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Create Fully Connected Network\nclass NN(nn.Module):\n    def __init__(self,input_size,num_classes):\n        super(NN, self).__init__()\n        self.fc1 = nn.Linear(input_size ,50)\n        self.fc2 = nn.Linear(50, num_classes)\n    \n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n    ","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hyperparameter\ninput_size = 784\nnum_classes = 10\nlearning_rate = 0.001\nbatch_size = 64\nnum_epochs = 1\n","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pwd","execution_count":5,"outputs":[{"output_type":"stream","text":"/kaggle/working\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir dataset\n!ls","execution_count":6,"outputs":[{"output_type":"stream","text":"__notebook_source__.ipynb  dataset\r\n","name":"stdout"}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Load Data\ntrain_dataset = datasets.MNIST(root = '/kaggle/working/dataset/',train = True,transform = transforms.ToTensor(),download = True)\n","execution_count":7,"outputs":[{"output_type":"stream","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /kaggle/working/dataset/MNIST/raw/train-images-idx3-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f675e5e805d64dbd9da7fb8dbfcd1422"}},"metadata":{}},{"output_type":"stream","text":"Extracting /kaggle/working/dataset/MNIST/raw/train-images-idx3-ubyte.gz to /kaggle/working/dataset/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /kaggle/working/dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62b80db9c3e747f2ae012f1d4b19675c"}},"metadata":{}},{"output_type":"stream","text":"Extracting /kaggle/working/dataset/MNIST/raw/train-labels-idx1-ubyte.gz to /kaggle/working/dataset/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /kaggle/working/dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e22a8f6f5c1f47e59e6f18a2b79132eb"}},"metadata":{}},{"output_type":"stream","text":"Extracting /kaggle/working/dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to /kaggle/working/dataset/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /kaggle/working/dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n\n\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"426191fa17774ef7894442dd155f83cf"}},"metadata":{}},{"output_type":"stream","text":"Extracting /kaggle/working/dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to /kaggle/working/dataset/MNIST/raw\nProcessing...\nDone!\n","name":"stdout"},{"output_type":"stream","text":"/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"Dataset MNIST\n    Number of datapoints: 60000\n    Root location: /kaggle/working/dataset/\n    Split: Train\n    StandardTransform\nTransform: ToTensor()"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(dataset = train_dataset,batch_size = batch_size,shuffle = True)\ntest_dataset = datasets.MNIST(root ='/kaggle/working/dataset/',train = False,transform = transforms.ToTensor(),download = True)\ntest_loader = DataLoader(dataset = test_dataset,batch_size = batch_size,shuffle = True)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Initialize network\nmodel = NN(input_size = input_size,num_classes = num_classes).to(device)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(),lr = learning_rate)\n","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train Network\nfor epoch in range(num_epochs):\n    for batch_idx,(data,targets) in enumerate(train_loader):\n        # get data to cuda if possible\n        data = data.to(device = device)\n        targets = targets.to(device = device)\n        \n        # Get to correct shape\n        data = data.reshape(data.shape[0], -1)\n        \n        # forward\n        scores = model(data)\n        loss = criterion(scores, targets)\n        \n        #backward\n        optimizer.zero_grad()\n        loss.backward()\n        \n        # gradient descent or adam step\n        optimizer.step()\n        \n","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check accuracy on training & test to see how good our model\ndef check_accuracy(loader,model):\n    if loader.dataset.train:\n        print(\"Checking accuracy on training data\")\n    else:\n        print(\"Checking accuracy on test data\")\n        \n    num_correct = 0\n    num_samples = 0\n    model.eval()\n    \n    with torch.no_grad():\n        for x, y in loader:\n            x = x.to(device = device)\n            y = y.to(device = device)\n            x = x.reshape(x.shape[0],-1)\n            \n            scores = model(x)\n            _,predictions = scores.max(1)\n            num_correct += (predictions == y).sum()\n            num_samples += predictions.size(0)\n            \n        print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n        \n    model.train()\n    \ncheck_accuracy(train_loader, model)\ncheck_accuracy(test_loader,model)\n","execution_count":16,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'loader' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-7dbb75f6cde3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-7dbb75f6cde3>\u001b[0m in \u001b[0;36mcheck_accuracy\u001b[0;34m(oader, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check accuracy on training & test to see how good our model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Checking accuracy on training data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'loader' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}